{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkillExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH2X1iUGFe7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0e2e5f60-cf1a-4e77-862b-cfc194239328"
      },
      "source": [
        "!git clone https://github.com/dnikolic98/CV-skill-extraction.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CV-skill-extraction'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 314 (delta 0), reused 3 (delta 0), pack-reused 302\u001b[K\n",
            "Receiving objects: 100% (314/314), 59.43 MiB | 29.26 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k_hffrNF9vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "303e827f-7b99-4e08-c584-acf595f1eedd"
      },
      "source": [
        "cd CV-skill-extraction/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CV-skill-extraction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVQjVcpmGX1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b2ef905-edca-4658-c820-eb790f2ea47e"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"all\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffRoJl4RLjFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "01eb997b-f5e2-4d1d-ba51-fc4f84366a81"
      },
      "source": [
        "!python training_dummy.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-06-27 06:48:54.002978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-27 06:49:00.896436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-27 06:49:00.901709: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-06-27 06:49:00.901756: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (262bad216d0c): /proc/driver/nvidia/version does not exist\n",
            "2020-06-27 06:49:00.908674: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2249995000 Hz\n",
            "2020-06-27 06:49:00.909137: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6369180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-27 06:49:00.909188: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "                                  cv  ...                                            skill_y\n",
            "0                   Vb.Net Developer  ...  \\n• Programming language: C, C++, Java\\n• Orac...\n",
            "1          .NET Developer / Engineer  ...  Database (Less than 1 year), HTML (Less than 1...\n",
            "2     Academic / Guidance Counselor   ...                                           Teradata\n",
            "3                 Account Executive   ...  ❖ Operating Environment: […] Windows95/98/XP/N...\n",
            "4  Account Manager / Representative   ...  EARCH ENGINE MARKETING (2 years), SEM (2 years...\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "Vb.Net Developer\n",
            "['']\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"training_dummy.py\", line 35, in <module>\n",
            "    phr_vec, cox_vec, phr_cox_vec, y = pp.preprocess(phrases,context, np_tags, context_tags, df[\"skill_y\"][i].split())\n",
            "  File \"/content/CV-skill-extraction/preprocessor.py\", line 53, in preprocess\n",
            "    current_phrase_vec = self.concat(noun_phrases[i], np_tags[i])\n",
            "  File \"/content/CV-skill-extraction/preprocessor.py\", line 24, in concat\n",
            "    ret_array = np.reshape(self.featureVector.vectorise(phrase[0], tags[0]), (1,-1))\n",
            "IndexError: string index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_TjDqZlXKdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from preprocessor import Preprocessor\n",
        "from inputExtractor import InputExtractor\n",
        "from skillExtractNN import SkillsExtractorNN\n",
        "from textFormater import TextFormater\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "in_extractor = InputExtractor()\n",
        "pp = Preprocessor()\n",
        "tf = TextFormater()\n",
        "\n",
        "word_features_dim, dense_features_dim = pp.getDim()\n",
        "clf = SkillsExtractorNN(word_features_dim, dense_features_dim)\n",
        "\n",
        "path = \"saved/dummy/model(0_14444445073604584).h5\"\n",
        "clf.load(path)\n",
        "def pre_process(text):\n",
        "    \n",
        "    # lowercase\n",
        "    text=text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    return text\n",
        "print(\"Keywords: \\n\")\n",
        "counter = 0\n",
        "#prepare cv and return predictions\n",
        "with open('data.txt') as file_obj:\n",
        "  for line in file_obj:\n",
        "    if counter==10:\n",
        "      break\n",
        "    counter += 1\n",
        "    line = pre_process(line)\n",
        "    cv = tf.format(line)\n",
        "    phrases, context, np_tags, context_tags = in_extractor.extract(cv)\n",
        "    phr_vec, cox_vec, phr_cox_vec = pp.preprocess(phrases,context, np_tags, context_tags)\n",
        "    predicted = clf.predict(np.array(phr_vec), np.array(cox_vec), np.array(phr_cox_vec))\n",
        "\n",
        "    \n",
        "    for i in range(len(predicted)):\n",
        "      if(np.argmax(predicted[i]) == 1):\n",
        "        print(phrases[i])\n",
        "    print('\\n')\n",
        "# cv = open('predict.txt', 'r').read()\n",
        "# cv = tf.format(cv)\n",
        "# phrases, context, np_tags, context_tags = in_extractor.extract(cv)\n",
        "# phr_vec, cox_vec, phr_cox_vec = pp.preprocess(phrases,context, np_tags, context_tags)\n",
        "# predicted = clf.predict(np.array(phr_vec), np.array(cox_vec), np.array(phr_cox_vec))\n",
        "\n",
        "# for i in range(len(predicted)):\n",
        "#     if(np.argmax(predicted[i]) == 1):\n",
        "#         print(phrases[i])\n",
        "# print(predicted)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVNIMrKhYE67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "84ab50d0-5548-42f0-f08e-b209663649ff"
      },
      "source": [
        "!python training_dummy.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-06-27 10:45:23.491304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-27 10:45:29.814607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-27 10:45:29.818326: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-06-27 10:45:29.818365: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a947d4c60560): /proc/driver/nvidia/version does not exist\n",
            "2020-06-27 10:45:29.823594: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\n",
            "2020-06-27 10:45:29.823850: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x761f180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-27 10:45:29.823884: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Epoch 1/1000\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 2.2154 - accuracy: 0.8556 - val_loss: 13.8034 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 2.2154 - accuracy: 0.8556 - val_loss: 13.8034 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 2.2154 - accuracy: 0.8556 - val_loss: 13.8034 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 2.2154 - accuracy: 0.8556 - val_loss: 13.8034 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 2.2154 - accuracy: 0.8556 - val_loss: 13.8034 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 2.2154 - accuracy: 0.8556 - val_loss: 13.8034 - val_accuracy: 0.1000\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUaw9n7uMbIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8b5a14f-0e59-45a7-9b7a-393a0b3955bc"
      },
      "source": [
        "!python predicting.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-27 11:02:07.214714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-27 11:02:12.641747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-27 11:02:12.645743: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-06-27 11:02:12.645799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a947d4c60560): /proc/driver/nvidia/version does not exist\n",
            "2020-06-27 11:02:12.652978: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\n",
            "2020-06-27 11:02:12.653282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x40cefc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-27 11:02:12.653320: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "Keywords: \n",
            "\n",
            "array([[8250.278,    0.   ],\n",
            "       [8250.407,    0.   ],\n",
            "       [8250.331,    0.   ],\n",
            "       [8250.349,    0.   ],\n",
            "       [8250.249,    0.   ],\n",
            "       [8250.254,    0.   ],\n",
            "       [8250.256,    0.   ],\n",
            "       [8250.326,    0.   ],\n",
            "       [8250.248,    0.   ],\n",
            "       [8250.275,    0.   ],\n",
            "       [8250.273,    0.   ]], dtype=float32)\n",
            "['the design',\n",
            " 'construction',\n",
            " 'operation',\n",
            " 'use',\n",
            " 'computer',\n",
            " 'control',\n",
            " 'sensory feedback',\n",
            " 'information',\n",
            " 'processing',\n",
            " 'functionality',\n",
            " 'research']\n",
            "\n",
            "\n",
            "array([[8250.289,    0.   ],\n",
            "       [8250.304,    0.   ],\n",
            "       [8250.313,    0.   ],\n",
            "       [8250.244,    0.   ],\n",
            "       [8250.292,    0.   ],\n",
            "       [8250.25 ,    0.   ],\n",
            "       [8250.264,    0.   ],\n",
            "       [8250.23 ,    0.   ],\n",
            "       [8250.428,    0.   ],\n",
            "       [8250.243,    0.   ],\n",
            "       [8250.205,    0.   ],\n",
            "       [8250.247,    0.   ],\n",
            "       [8250.247,    0.   ],\n",
            "       [8250.282,    0.   ],\n",
            "       [8250.298,    0.   ],\n",
            "       [8250.304,    0.   ],\n",
            "       [8250.211,    0.   ],\n",
            "       [8250.309,    0.   ],\n",
            "       [8250.289,    0.   ],\n",
            "       [8250.231,    0.   ],\n",
            "       [8250.239,    0.   ],\n",
            "       [8250.271,    0.   ],\n",
            "       [8250.249,    0.   ],\n",
            "       [8250.297,    0.   ],\n",
            "       [8250.293,    0.   ],\n",
            "       [8250.338,    0.   ],\n",
            "       [8250.32 ,    0.   ],\n",
            "       [8250.289,    0.   ],\n",
            "       [8250.39 ,    0.   ],\n",
            "       [8250.381,    0.   ],\n",
            "       [8250.248,    0.   ],\n",
            "       [8250.269,    0.   ],\n",
            "       [8250.247,    0.   ],\n",
            "       [8250.231,    0.   ],\n",
            "       [8250.271,    0.   ],\n",
            "       [8250.317,    0.   ],\n",
            "       [8250.293,    0.   ],\n",
            "       [8250.27 ,    0.   ],\n",
            "       [8250.232,    0.   ],\n",
            "       [8250.265,    0.   ],\n",
            "       [8250.293,    0.   ],\n",
            "       [8250.264,    0.   ],\n",
            "       [8250.266,    0.   ],\n",
            "       [8250.26 ,    0.   ],\n",
            "       [8250.281,    0.   ],\n",
            "       [8250.354,    0.   ],\n",
            "       [8250.404,    0.   ],\n",
            "       [8250.203,    0.   ],\n",
            "       [8250.278,    0.   ],\n",
            "       [8250.346,    0.   ],\n",
            "       [8250.271,    0.   ],\n",
            "       [8250.337,    0.   ],\n",
            "       [8250.335,    0.   ],\n",
            "       [8250.423,    0.   ],\n",
            "       [8250.482,    0.   ],\n",
            "       [8250.241,    0.   ],\n",
            "       [8250.254,    0.   ],\n",
            "       [8250.306,    0.   ],\n",
            "       [8250.252,    0.   ],\n",
            "       [8250.258,    0.   ],\n",
            "       [8250.273,    0.   ],\n",
            "       [8250.281,    0.   ],\n",
            "       [8250.307,    0.   ],\n",
            "       [8250.213,    0.   ],\n",
            "       [8250.212,    0.   ]], dtype=float32)\n",
            "['personality',\n",
            " 'development',\n",
            " 'communication',\n",
            " 'skill',\n",
            " 'own identity',\n",
            " 'personality',\n",
            " 'development',\n",
            " 'enduring pattern',\n",
            " 'the dominant view',\n",
            " 'the field',\n",
            " 'personality',\n",
            " 'psychology',\n",
            " 'today',\n",
            " 'personality',\n",
            " 'the lifespan',\n",
            " 'adult',\n",
            " 'personality',\n",
            " 'a basis',\n",
            " 'infant temperament',\n",
            " 'https',\n",
            " 'wikipedia',\n",
            " 'org',\n",
            " 'wiki',\n",
            " 'temperament temperament',\n",
            " 'meaning',\n",
            " 'disposition',\n",
            " 'behavior',\n",
            " 'life',\n",
            " 'language',\n",
            " 'conscious self',\n",
            " 'representation',\n",
            " 'factor',\n",
            " 'model',\n",
            " 'https',\n",
            " 'wikipedia',\n",
            " 'org',\n",
            " 'wiki',\n",
            " 'personality',\n",
            " 'personality',\n",
            " 'childhood',\n",
            " 'temperament',\n",
            " 'personality',\n",
            " 'neuroticism',\n",
            " 'extraversion',\n",
            " 'openness',\n",
            " 'agreeableness',\n",
            " 'conscientiousness',\n",
            " 'gene',\n",
            " 'environment',\n",
            " 'the process',\n",
            " 'the expression',\n",
            " 'the process',\n",
            " 'the development',\n",
            " 'the process',\n",
            " 'non family',\n",
            " 'the behavior',\n",
            " 'a genotype',\n",
            " 'this principle',\n",
            " 'gene',\n",
            " 'environment',\n",
            " 'person',\n",
            " 'situation',\n",
            " 'the continuity',\n",
            " 'personality',\n",
            " 'the lifespan']\n",
            "\n",
            "\n",
            "array([[8250.434 ,    0.    ],\n",
            "       [8250.387 ,    0.    ],\n",
            "       [8250.3955,    0.    ],\n",
            "       [8250.3   ,    0.    ],\n",
            "       [8250.482 ,    0.    ],\n",
            "       [8250.314 ,    0.    ],\n",
            "       [8250.248 ,    0.    ],\n",
            "       [8250.287 ,    0.    ],\n",
            "       [8250.254 ,    0.    ],\n",
            "       [8250.308 ,    0.    ],\n",
            "       [8250.328 ,    0.    ],\n",
            "       [8250.49  ,    0.    ],\n",
            "       [8250.298 ,    0.    ],\n",
            "       [8250.252 ,    0.    ],\n",
            "       [8250.251 ,    0.    ],\n",
            "       [8250.253 ,    0.    ],\n",
            "       [8250.248 ,    0.    ],\n",
            "       [8250.283 ,    0.    ],\n",
            "       [8250.26  ,    0.    ],\n",
            "       [8250.27  ,    0.    ],\n",
            "       [8250.242 ,    0.    ],\n",
            "       [8250.267 ,    0.    ],\n",
            "       [8250.232 ,    0.    ],\n",
            "       [8250.247 ,    0.    ],\n",
            "       [8250.334 ,    0.    ],\n",
            "       [8250.306 ,    0.    ],\n",
            "       [8250.275 ,    0.    ],\n",
            "       [8250.354 ,    0.    ],\n",
            "       [8250.394 ,    0.    ],\n",
            "       [8250.216 ,    0.    ],\n",
            "       [8250.338 ,    0.    ],\n",
            "       [8250.332 ,    0.    ],\n",
            "       [8250.346 ,    0.    ],\n",
            "       [8250.278 ,    0.    ],\n",
            "       [8250.259 ,    0.    ],\n",
            "       [8250.385 ,    0.    ],\n",
            "       [8250.303 ,    0.    ],\n",
            "       [8250.211 ,    0.    ],\n",
            "       [8250.197 ,    0.    ],\n",
            "       [8250.205 ,    0.    ]], dtype=float32)\n",
            "['learn ethical hacking',\n",
            " 'scratch',\n",
            " 'an ethical hacker',\n",
            " 'computer',\n",
            " 'black hat',\n",
            " 'security',\n",
            " 'this comprehensive course',\n",
            " 'ethical hacking',\n",
            " 'this course',\n",
            " 'no prior knowledge',\n",
            " 'the end',\n",
            " 'black hat',\n",
            " 'security',\n",
            " 'this course',\n",
            " 'the theory',\n",
            " 'penetration',\n",
            " 'software',\n",
            " 'linux',\n",
            " 'mac',\n",
            " 'x',\n",
            " 'everything',\n",
            " 'example',\n",
            " 'computer',\n",
            " 'the course',\n",
            " 'a number',\n",
            " 'each section',\n",
            " 'a penetration',\n",
            " 'field',\n",
            " 'the target',\n",
            " 'system',\n",
            " 'this system',\n",
            " 'hack',\n",
            " 'this system',\n",
            " 'this course',\n",
            " 'a beginner',\n",
            " 'advanced level',\n",
            " 'the time',\n",
            " 'penetration',\n",
            " 'certificate',\n",
            " 'completion']\n",
            "\n",
            "\n",
            "array([[8250.262 ,    0.    ],\n",
            "       [8250.293 ,    0.    ],\n",
            "       [8250.246 ,    0.    ],\n",
            "       [8250.326 ,    0.    ],\n",
            "       [8250.286 ,    0.    ],\n",
            "       [8250.311 ,    0.    ],\n",
            "       [8250.332 ,    0.    ],\n",
            "       [8250.179 ,    0.    ],\n",
            "       [8250.263 ,    0.    ],\n",
            "       [8250.232 ,    0.    ],\n",
            "       [8250.231 ,    0.    ],\n",
            "       [8250.289 ,    0.    ],\n",
            "       [8250.3125,    0.    ],\n",
            "       [8250.366 ,    0.    ],\n",
            "       [8250.378 ,    0.    ],\n",
            "       [8250.175 ,    0.    ],\n",
            "       [8250.276 ,    0.    ],\n",
            "       [8250.221 ,    0.    ],\n",
            "       [8250.277 ,    0.    ],\n",
            "       [8250.256 ,    0.    ],\n",
            "       [8250.351 ,    0.    ],\n",
            "       [8250.158 ,    0.    ]], dtype=float32)\n",
            "['master',\n",
            " 'web',\n",
            " 'design',\n",
            " 'photoshop',\n",
            " 'photoshop',\n",
            " 'no coding',\n",
            " 'beautiful web',\n",
            " 'design',\n",
            " 'a practical knowledge',\n",
            " 'adobe',\n",
            " 'photoshop',\n",
            " 'this course',\n",
            " 'photoshop',\n",
            " 'excite end',\n",
            " 'a career',\n",
            " 'web design',\n",
            " 'photoshop',\n",
            " 'the design',\n",
            " 'industry',\n",
            " 'knowledge',\n",
            " 'understanding',\n",
            " 'web design']\n",
            "\n",
            "\n",
            "array([[8250.241,    0.   ],\n",
            "       [8250.225,    0.   ],\n",
            "       [8250.247,    0.   ],\n",
            "       [8250.265,    0.   ],\n",
            "       [8250.214,    0.   ],\n",
            "       [8250.202,    0.   ],\n",
            "       [8250.211,    0.   ],\n",
            "       [8250.262,    0.   ],\n",
            "       [8250.323,    0.   ],\n",
            "       [8250.442,    0.   ],\n",
            "       [8250.353,    0.   ],\n",
            "       [8250.344,    0.   ],\n",
            "       [8250.244,    0.   ],\n",
            "       [8250.241,    0.   ],\n",
            "       [8250.238,    0.   ],\n",
            "       [8250.321,    0.   ],\n",
            "       [8250.384,    0.   ],\n",
            "       [8250.323,    0.   ],\n",
            "       [8250.244,    0.   ],\n",
            "       [8250.348,    0.   ],\n",
            "       [8250.412,    0.   ]], dtype=float32)\n",
            "['react',\n",
            " 'js',\n",
            " 'web',\n",
            " 'development',\n",
            " 'bootcamp',\n",
            " 'the react',\n",
            " 'js',\n",
            " 'a strong foundation',\n",
            " 'the core',\n",
            " 'the new content',\n",
            " 'modern react',\n",
            " 'development',\n",
            " 'the react engine',\n",
            " 'exploration',\n",
            " 'the overall big picture',\n",
            " 'web',\n",
            " 'development',\n",
            " 'the course',\n",
            " 'the tutorial',\n",
            " 'learn',\n",
            " 'the right']\n",
            "\n",
            "\n",
            "array([[8250.24 ,    0.   ],\n",
            "       [8250.369,    0.   ],\n",
            "       [8250.26 ,    0.   ],\n",
            "       [8250.258,    0.   ],\n",
            "       [8250.372,    0.   ],\n",
            "       [8250.291,    0.   ],\n",
            "       [8250.339,    0.   ],\n",
            "       [8250.336,    0.   ],\n",
            "       [8250.314,    0.   ],\n",
            "       [8250.33 ,    0.   ],\n",
            "       [8250.349,    0.   ],\n",
            "       [8250.265,    0.   ],\n",
            "       [8250.306,    0.   ],\n",
            "       [8250.223,    0.   ],\n",
            "       [8250.304,    0.   ],\n",
            "       [8250.304,    0.   ],\n",
            "       [8250.288,    0.   ],\n",
            "       [8250.31 ,    0.   ],\n",
            "       [8250.255,    0.   ],\n",
            "       [8250.293,    0.   ],\n",
            "       [8250.377,    0.   ],\n",
            "       [8250.332,    0.   ],\n",
            "       [8250.387,    0.   ],\n",
            "       [8250.307,    0.   ],\n",
            "       [8250.244,    0.   ]], dtype=float32)\n",
            "['beginner',\n",
            " 'programming',\n",
            " 'oop',\n",
            " 'stl',\n",
            " 'game',\n",
            " 'system',\n",
            " 'application',\n",
            " 'development',\n",
            " 'language',\n",
            " 'a badge',\n",
            " 'honor',\n",
            " 'software',\n",
            " 'language',\n",
            " 'resume',\n",
            " 'a job',\n",
            " 'interview',\n",
            " 'c',\n",
            " 'language',\n",
            " 'the top programming',\n",
            " 'popularity',\n",
            " 'the top',\n",
            " 'learn',\n",
            " 'program',\n",
            " 'powerful programming',\n",
            " 'today']\n",
            "\n",
            "\n",
            "array([[8250.224,    0.   ],\n",
            "       [8250.267,    0.   ],\n",
            "       [8250.293,    0.   ],\n",
            "       [8250.233,    0.   ],\n",
            "       [8250.253,    0.   ],\n",
            "       [8250.295,    0.   ],\n",
            "       [8250.222,    0.   ],\n",
            "       [8250.267,    0.   ],\n",
            "       [8250.266,    0.   ],\n",
            "       [8250.266,    0.   ],\n",
            "       [8250.346,    0.   ],\n",
            "       [8250.229,    0.   ],\n",
            "       [8250.22 ,    0.   ],\n",
            "       [8250.173,    0.   ],\n",
            "       [8250.328,    0.   ],\n",
            "       [8250.408,    0.   ],\n",
            "       [8250.297,    0.   ],\n",
            "       [8250.299,    0.   ],\n",
            "       [8250.351,    0.   ],\n",
            "       [8250.303,    0.   ],\n",
            "       [8250.228,    0.   ],\n",
            "       [8250.223,    0.   ],\n",
            "       [8250.402,    0.   ],\n",
            "       [8250.367,    0.   ],\n",
            "       [8250.283,    0.   ],\n",
            "       [8250.188,    0.   ],\n",
            "       [8250.125,    0.   ]], dtype=float32)\n",
            "['ocean',\n",
            " 'node js',\n",
            " 'learn',\n",
            " 'node',\n",
            " 'js',\n",
            " 'real world',\n",
            " 'node',\n",
            " 'express',\n",
            " 'mongodb',\n",
            " 'mocha',\n",
            " 'the complete node',\n",
            " 'js',\n",
            " 'developer',\n",
            " 'course',\n",
            " 'node',\n",
            " 'express',\n",
            " 'mongoose',\n",
            " 'the entire course',\n",
            " 'a single goal',\n",
            " 'a professional node',\n",
            " 'developer',\n",
            " 'capable',\n",
            " 'real world',\n",
            " 'production',\n",
            " 'edge',\n",
            " 'es es',\n",
            " 'javascript']\n",
            "\n",
            "\n",
            "array([[8250.329 ,    0.    ],\n",
            "       [8250.255 ,    0.    ],\n",
            "       [8250.255 ,    0.    ],\n",
            "       [8250.336 ,    0.    ],\n",
            "       [8250.3   ,    0.    ],\n",
            "       [8250.286 ,    0.    ],\n",
            "       [8250.301 ,    0.    ],\n",
            "       [8250.293 ,    0.    ],\n",
            "       [8250.339 ,    0.    ],\n",
            "       [8250.331 ,    0.    ],\n",
            "       [8250.254 ,    0.    ],\n",
            "       [8250.186 ,    0.    ],\n",
            "       [8250.238 ,    0.    ],\n",
            "       [8250.445 ,    0.    ],\n",
            "       [8250.463 ,    0.    ],\n",
            "       [8250.267 ,    0.    ],\n",
            "       [8250.215 ,    0.    ],\n",
            "       [8250.17  ,    0.    ],\n",
            "       [8250.312 ,    0.    ],\n",
            "       [8250.298 ,    0.    ],\n",
            "       [8250.309 ,    0.    ],\n",
            "       [8250.424 ,    0.    ],\n",
            "       [8250.365 ,    0.    ],\n",
            "       [8250.357 ,    0.    ],\n",
            "       [8250.232 ,    0.    ],\n",
            "       [8250.336 ,    0.    ],\n",
            "       [8250.4375,    0.    ],\n",
            "       [8250.255 ,    0.    ],\n",
            "       [8250.272 ,    0.    ],\n",
            "       [8250.368 ,    0.    ],\n",
            "       [8250.372 ,    0.    ],\n",
            "       [8250.332 ,    0.    ],\n",
            "       [8250.241 ,    0.    ],\n",
            "       [8250.202 ,    0.    ],\n",
            "       [8250.215 ,    0.    ],\n",
            "       [8250.259 ,    0.    ],\n",
            "       [8250.261 ,    0.    ]], dtype=float32)\n",
            "['complete guitar',\n",
            " 'system',\n",
            " 'beginner',\n",
            " 'every struggle',\n",
            " 'guitar',\n",
            " 'this course',\n",
            " '_free pass_',\n",
            " 'guitar',\n",
            " 'the point_',\n",
            " 'complete online',\n",
            " 'guitar',\n",
            " 'course',\n",
            " 'the videos',\n",
            " 'the exact same order',\n",
            " 'a huge positive change',\n",
            " 'playing',\n",
            " 'pdf',\n",
            " 'video',\n",
            " 'a pc',\n",
            " 'mac',\n",
            " 'a ipad iphone',\n",
            " 'android app',\n",
            " 'ready',\n",
            " 'track',\n",
            " 'a breeze',\n",
            " 'udemy',\n",
            " 'a great way',\n",
            " 'track',\n",
            " 'the entire course',\n",
            " 'step',\n",
            " 'step',\n",
            " 'practice',\n",
            " 'the _right practice_',\n",
            " 'style',\n",
            " 'chord',\n",
            " 'picking',\n",
            " 'fingerpicking']\n",
            "\n",
            "\n",
            "array([[8250.332 ,    0.    ],\n",
            "       [8250.4   ,    0.    ],\n",
            "       [8250.318 ,    0.    ],\n",
            "       [8250.315 ,    0.    ],\n",
            "       [8250.383 ,    0.    ],\n",
            "       [8250.297 ,    0.    ],\n",
            "       [8250.243 ,    0.    ],\n",
            "       [8250.346 ,    0.    ],\n",
            "       [8250.321 ,    0.    ],\n",
            "       [8250.311 ,    0.    ],\n",
            "       [8250.348 ,    0.    ],\n",
            "       [8250.388 ,    0.    ],\n",
            "       [8250.345 ,    0.    ],\n",
            "       [8250.337 ,    0.    ],\n",
            "       [8250.375 ,    0.    ],\n",
            "       [8250.367 ,    0.    ],\n",
            "       [8250.355 ,    0.    ],\n",
            "       [8250.213 ,    0.    ],\n",
            "       [8250.213 ,    0.    ],\n",
            "       [8250.239 ,    0.    ],\n",
            "       [8250.27  ,    0.    ],\n",
            "       [8250.258 ,    0.    ],\n",
            "       [8250.3125,    0.    ],\n",
            "       [8250.294 ,    0.    ],\n",
            "       [8250.279 ,    0.    ],\n",
            "       [8250.311 ,    0.    ],\n",
            "       [8250.257 ,    0.    ],\n",
            "       [8250.211 ,    0.    ],\n",
            "       [8250.324 ,    0.    ],\n",
            "       [8250.267 ,    0.    ],\n",
            "       [8250.346 ,    0.    ],\n",
            "       [8250.29  ,    0.    ],\n",
            "       [8250.281 ,    0.    ],\n",
            "       [8250.278 ,    0.    ],\n",
            "       [8250.3545,    0.    ],\n",
            "       [8250.295 ,    0.    ],\n",
            "       [8250.314 ,    0.    ],\n",
            "       [8250.305 ,    0.    ],\n",
            "       [8250.279 ,    0.    ],\n",
            "       [8250.201 ,    0.    ],\n",
            "       [8250.193 ,    0.    ],\n",
            "       [8250.288 ,    0.    ],\n",
            "       [8250.216 ,    0.    ],\n",
            "       [8250.324 ,    0.    ],\n",
            "       [8250.262 ,    0.    ],\n",
            "       [8250.359 ,    0.    ],\n",
            "       [8250.331 ,    0.    ]], dtype=float32)\n",
            "['science',\n",
            " 'exercise',\n",
            " 'basic science',\n",
            " 'science',\n",
            " 'exercise',\n",
            " 'an improved physiological understanding',\n",
            " 'body',\n",
            " 'health',\n",
            " 'training',\n",
            " 'a number',\n",
            " 'body',\n",
            " 'order',\n",
            " 'the physical stress',\n",
            " 'exercise',\n",
            " 'carbohydrate',\n",
            " 'fat',\n",
            " 'protein',\n",
            " 'metabolism',\n",
            " 'muscle',\n",
            " 'soreness',\n",
            " 'fatigue',\n",
            " 'the effectiveness',\n",
            " 'performance',\n",
            " 'this new knowledge',\n",
            " 'nutrition',\n",
            " 'heart',\n",
            " 'rate',\n",
            " 'monitoring',\n",
            " 'total daily caloric expenditure',\n",
            " 'body',\n",
            " 'mass',\n",
            " 'index',\n",
            " 'the scientific evidence',\n",
            " 'the health',\n",
            " 'exercise',\n",
            " 'the prevention',\n",
            " 'treatment',\n",
            " 'heart',\n",
            " 'disease',\n",
            " 'cancer',\n",
            " 'obesity',\n",
            " 'loss',\n",
            " 'depression',\n",
            " 'dementia',\n",
            " 'moreover',\n",
            " 'fit exercise',\n",
            " 'suitable manner']\n",
            "\n",
            "\n",
            "array([[8250.218,    0.   ],\n",
            "       [8250.208,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.189,    0.   ],\n",
            "       [8250.22 ,    0.   ],\n",
            "       [8250.237,    0.   ],\n",
            "       [8250.382,    0.   ],\n",
            "       [8250.301,    0.   ]], dtype=float32)\n",
            "['fundamental analysis',\n",
            " 'fundamental analysisfundamental analysisfundamental analysisfundamental '\n",
            " 'analysisfundamental analysisfundamental analysisfundamental '\n",
            " 'analysisfundamental analysisfundamental analysisfundamental analysis',\n",
            " 'priyansh',\n",
            " 'kepriyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'sarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'priyansh',\n",
            " 'kesarwani',\n",
            " 'kesarwani',\n",
            " 'investment',\n",
            " 'share']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}